{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f780a5d-fc68-4123-b8e2-2a966c3966bd",
   "metadata": {},
   "source": [
    "### Simplified Code for Image Recognition b/w Cat & Flower Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e0d65aa5-7fc4-4770-a599-dac3f25c82bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9b7a11a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image  # Add this import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "41f42e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Define the SwinTransformer model (simplified)\n",
    "class SwinTransformer(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(SwinTransformer, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 96, kernel_size=4, stride=4),\n",
    "            nn.LayerNorm([96, 56, 56]),\n",
    "            nn.GELU(),\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "        self.classifier = nn.Linear(96, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "35c6998d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Data transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a26ff48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data = datasets.ImageFolder('C:/Users/sharm/Downloads/Cat_train', transform=transform)\n",
    "test_data = datasets.ImageFolder('C:/Users/sharm/Downloads/Cat_test', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "model = SwinTransformer().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=0.3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "66d99126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "def train(epochs):\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a1fbfc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test function\n",
    "def test():\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print(f'Accuracy on test images: {100 * correct / total}%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "17ea97e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.7219\n",
      "Epoch [2/10], Loss: 0.7098\n",
      "Epoch [3/10], Loss: 0.7033\n",
      "Epoch [4/10], Loss: 0.6998\n",
      "Epoch [5/10], Loss: 0.6981\n",
      "Epoch [6/10], Loss: 0.6971\n",
      "Epoch [7/10], Loss: 0.6962\n",
      "Epoch [8/10], Loss: 0.6950\n",
      "Epoch [9/10], Loss: 0.6936\n",
      "Epoch [10/10], Loss: 0.6919\n",
      "Accuracy on test images: 75.0%\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train(epochs=10)\n",
    "\n",
    "# Test the model\n",
    "test()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "4c28aa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict on a single image\n",
    "def predict_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    image = transform(image).unsqueeze(0).to(device)\n",
    "    \n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        output = model(image)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "    \n",
    "    return train_data.classes[predicted.item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c358b43c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: class_2\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "custom_image_path = \"C:/Users/sharm/Downloads/Cat_test/class_2/s1.jpg\"\n",
    "prediction = predict_image(custom_image_path)\n",
    "print(f\"Prediction: {prediction}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d5f24330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 0.75\n",
      "F1 Score: 0.7333333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "\n",
    "recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1 Score: {f1}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b21c352",
   "metadata": {},
   "source": [
    "In the above code, the learning rate values influence the accuracy but they mostly fluctuate between 50-75.\n",
    "\n",
    "3e-3 = 75% accuracy\n",
    "\n",
    "3e-4 = 50% accuracy\n",
    "\n",
    "1e-4 = 75% accuracy\n",
    "\n",
    "1e-3 = 75% accuracy\n",
    "\n",
    "1e-2 = 50% accuracy\n",
    "\n",
    "2e-3 = 75% accuracy\n",
    "\n",
    "2e-4 = 50% accuracy\n",
    "\n",
    "5e-3 = 75% accuracy\n",
    "\n",
    "5e-4 = 75% accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171d8ea4",
   "metadata": {},
   "source": [
    "### Key Metrics Overview:\n",
    "\n",
    "Training Loss: The loss gradually decreases across the epochs, starting at 0.7219 in Epoch 1 and ending at 0.6919 in Epoch 10.\n",
    "\n",
    "Test Accuracy: The accuracy on the test images reaches 75.0%, which indicates relatively good performance on the validation set.\n",
    "\n",
    "### Key Observations:\n",
    "\n",
    "Steady Loss Reduction: The training loss steadily decreases, which suggests that the model is learning consistently and making progress toward convergence. This smooth reduction indicates the optimization process is functioning well.\n",
    "\n",
    "Higher Test Accuracy: The model achieves 75.0% accuracy on the test images, meaning it is correctly classifying three-quarters of the test samples. This is a significant improvement over random guessing and shows that the model has learned relevant patterns to distinguish between the two flower classes (Dandelion & Daisy).\n",
    "\n",
    "### Positive Findings:\n",
    "\n",
    "Effective Learning: The steady drop in training loss suggests that the model is not overfitting or underfitting and that its learning rate or other hyperparameters are likely well-tuned.\n",
    "\n",
    "Good Generalization: With a test accuracy of 75.0%, the model seems to generalize well from the training data to unseen test data. This indicates that it has successfully captured meaningful features of the flower classes.\n",
    "\n",
    "### Recommendations for Further Improvement:\n",
    "\n",
    "Increase Epochs: Running the model for more epochs might help further reduce the training loss and potentially improve test accuracy.\n",
    "\n",
    "Hyperparameter Tuning: Additional fine-tuning of hyperparameters (like learning rate, batch size, etc.) could help optimize the performance further.\n",
    "\n",
    "Data Augmentation: While the model seems to generalize well, introducing more advanced data augmentation techniques might further improve accuracy, especially if there’s noise or variations in the test data.\n",
    "\n",
    "Model Complexity: If more accuracy is required, increasing the model’s complexity (e.g., deeper layers, more attention heads in transformers) could be considered to better capture nuanced patterns in the flower dataset.\n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "The model is performing well with a 75% test accuracy and consistently decreasing loss. The model could benefit from further training and tuning, but it is already showing signs of effective learning and generalization to the flower dataset.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
